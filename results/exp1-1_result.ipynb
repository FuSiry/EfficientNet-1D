{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbasecondae8dfda97d29a42c49f2c56e1d99c796c",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-1. Kernel size in 1D-CNN: Is smaller is better?\n",
    "\n",
    "In 2D, it is known as using small size convolution kernel and stacking more layer is better,  \n",
    "1) 2 x (3x3) kernel (receptive field = 5x5)  \n",
    "2) 1 x (5x5) kernel (receptive field = 5x5)  \n",
    "1) is better since it has smaller number of parameter and better performance since it can give more non-linearity.  \n",
    "Is this works same in 1D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from result_utils import read_config, result_data, unique_average, visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "# of experiments: 13\n"
    }
   ],
   "source": [
    "CONFIG_FNAME = 'exp1-1'\n",
    "configs = read_config(CONFIG_FNAME)\n",
    "\n",
    "RESULT_ROOT_DIR = '../results/' + CONFIG_FNAME\n",
    "result_path = RESULT_ROOT_DIR + '/' + 'test_results.txt'\n",
    "results = []\n",
    "with open(result_path, 'r') as f:\n",
    "    for line in f:\n",
    "        x = line.strip().split(',')\n",
    "        acc = x[1]\n",
    "        results.append(acc)\n",
    "results = np.array(results, dtype=float)\n",
    "\n",
    "N = len(configs)\n",
    "print('# of experiments: %d'%N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Receptive 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "kernel_size=3, repeat=1: 0.9028\n"
    }
   ],
   "source": [
    "acc = results[0]\n",
    "print('kernel_size=3, repeat=1: %.4f'%acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Receptive 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "kernel_size=3, repeat=2: 0.8889\nkernel_size=5, repeat=1: 0.8750\n"
    }
   ],
   "source": [
    "acc1 = results[1]\n",
    "acc2 = results[2]\n",
    "print('kernel_size=3, repeat=2: %.4f'%acc1)\n",
    "print('kernel_size=5, repeat=1: %.4f'%acc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kernel_size=3, repeat=2 is better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Receptive 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "kernel_size=3, repeat=3: 0.9444\nkernel_size=7, repeat=1: 0.9167\n"
    }
   ],
   "source": [
    "acc1 = results[3]\n",
    "acc2 = results[4]\n",
    "print('kernel_size=3, repeat=3: %.4f'%acc1)\n",
    "print('kernel_size=7, repeat=1: %.4f'%acc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kernel_size=3, repeat=3 is better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Receptive 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "kernel_size=3, repeat=4: 0.8750\nkernel_size=9, repeat=1: 0.8750\n"
    }
   ],
   "source": [
    "acc1 = results[5]\n",
    "acc2 = results[6]\n",
    "print('kernel_size=3, repeat=4: %.4f'%acc1)\n",
    "print('kernel_size=9, repeat=1: %.4f'%acc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Receptive 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "kernel_size=3, repeat=5: 0.5417\nkernel_size=11, repeat=1: 0.9167\n"
    }
   ],
   "source": [
    "acc1 = results[7]\n",
    "acc2 = results[8]\n",
    "print('kernel_size=3, repeat=5: %.4f'%acc1)\n",
    "print('kernel_size=11, repeat=1: %.4f'%acc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kernel_size=11, repeat=1 is better.\n",
    "But it seems kernel size 3 case is not trained. It shoud be tested again.  \n",
    "Maybe this is because layer is too deep and learning rate is too high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Receptive 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "kernel_size=3, repeat=6: 0.2639\nkernel_size=13, repeat=1: 0.9444\n"
    }
   ],
   "source": [
    "acc1 = results[9]\n",
    "acc2 = results[10]\n",
    "print('kernel_size=3, repeat=6: %.4f'%acc1)\n",
    "print('kernel_size=13, repeat=1: %.4f'%acc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kernel_size=13, repeat=1 is better\n",
    "Similar as Receptive 11 case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Receptive 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "kernel_size=3, repeat=7: 0.4167\nkernel_size=15, repeat=1: 0.9028\n"
    }
   ],
   "source": [
    "acc1 = results[11]\n",
    "acc2 = results[12]\n",
    "print('kernel_size=3, repeat=7: %.4f'%acc1)\n",
    "print('kernel_size=15, repeat=1: %.4f'%acc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kernel_size=15, repeat=1 is better\n",
    "Similar as Receptive 11 case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, kernel size=13 is best option.  \n",
    "However, before receptive 11 case, stacking small layer convolution shows the better performance.  \n",
    "Therefore, in later experiment, kernel size 3 will be used since depth scale parameter will stack layers."
   ]
  }
 ]
}